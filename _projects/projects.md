---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

<style>
a:link {
  text-decoration: none;
}

a:visited {
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

a:active {
  text-decoration: underline;
}

.project-link {
  color: blue;
  text-decoration: underline;
}
</style>

### TIME Lab Research Project [Ongoing]

My work delves into the fascinating field of AI explainability and transparency, where I explore how complex AI models can become more understandable and trustworthy. In a world increasingly shaped by AI-driven decisions, ensuring that these systems are interpretable is both a technical challenge and a moral imperative.

Outputs:

[Graph Your Own Prompt](https://darcyddx.github.io/files/neurips25_graph_camera.pdf), Advances in Neural Information Processing Systems (NeurIPS) 2025

---
<!-- need to put images/videos in the left, words in the right -->

### ANU TechLauncher - TIME Labâ€™s TIME Space [Ongoing]

[TIME Lab](https://time.griffith.edu.au/) is a dynamic team of honours and master's students working on final-year research projects. Over the past year, the team has made significant strides, not only in research but also in achieving a healthy work-life balance. To celebrate this progress, TIME Lab aims to design a website, TIME Space, to showcase the memorable moments of the past year. TIME Space will be a fully interactive platform where photos loop endlessly, following the dynamic motion of the TIME Lab logo. Users will be able to engage with the space by selecting specific time frames, locations, or individuals involved in the memories, creating a personalized experience that brings the past year to life.

By undertaking this project, students will gain hands-on experience in full-stack development, designing and deploying a dynamic web application with advanced UX/UI features. They will enhance their skills in frontend and backend development, database management, and cloud deployment, while applying machine learning techniques for smart tagging and image processing. The project challenges students to solve real-world problems creatively, preparing them for professional environments and adding a portfolio-ready achievement to showcase their technical expertise.

This project combines cutting-edge technologies with a meaningful goal: bringing memories to life through an innovative, interactive platform. Students will work in a collaborative, supportive environment, tackling challenges across web development, data visualization, and user interaction. With immediate application in the TIME Lab, the project provides a visible, impactful outcome, offering both personal and professional fulfillment while building critical, in-demand skills.

Students undertaking this project will receive mentorship TIME Lab researchers, along with support from the ANU TechLauncher program, including access to workshops, industry connections, and project management tools. They will work in a collaborative environment, benefiting from feedback from peers and stakeholders. Key resources like cloud services, development platforms, and software tools for web development, machine learning, and UX/UI design will be provided. Regular technical guidance, testing support, and workshops on essential technologies will ensure students have everything needed to succeed.

---

### ANU TechLauncher - Active Vision Project [Completed]

The [TechLauncher program](https://comp.anu.edu.au/TechLauncher/) is for team-based activities at ANU, where the project and/or group activity undertaken is real, not synthetic.

The Active Vision project aims to develop an advanced computer vision system that analyzes the dynamics of tennis swings. Using cutting-edge machine learning techniques, this project focuses on capturing and analyzing motion data to provide players and coaches with detailed insights into swing mechanics. The system leverages high-speed cameras and advanced algorithms to track, interpret, and visualize the movements of a player's body and racket, enabling precise performance assessment and improvement.

Objectives include: (i) Develop analytical algorithms: Create robust algorithms capable of analyzing the captured motion data to identify key performance indicators (KPIs) such as swing speed, angle, and impact accuracy. (ii) Real-time feedback: Implement a real-time feedback system that provides immediate insights and suggestions to players, enhancing their ability to correct and refine their techniques on the spot. (iii) User-friendly interface: Develop an intuitive interface that allows users to easily interact with the system, view their performance data, and track their progress over time.

Outputs:

[2024 S2 Poster](https://leiwangr.github.io/files/24-S2-2-Active-Vision.png), [2025 S1 Poster](https://leiwangr.github.io/images/Poster.pdf), [Demo video](https://darcyddx.github.io/images/demo.MP4)

---

### Image Embedding Explorer [Completed]

We developed an innovative tool that allows users to visually navigate the high-dimensional space of image embeddings. By leveraging a technique known as projection pursuit, the tool creates dynamic 3D projections of the embedding space, offering an intuitive way to explore its structure. Each point in this space can be interactively rendered as the original image, making it easier to understand and interpret the relationships between images and their embeddings.

[Project paper](https://darcyddx.github.io/files/IEE.pdf)



