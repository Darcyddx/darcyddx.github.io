---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

<style>
a:link {
  text-decoration: none;
}

a:visited {
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

a:active {
  text-decoration: underline;
}

.project-link {
  color: blue;
  text-decoration: underline;
}
</style>

### ARC Research Hub Research Project [Ongoing]

My work delves into the fascinating field of AI explainability and transparency, where I explore how complex AI models can become more understandable and trustworthy. In a world increasingly shaped by AI-driven decisions, ensuring that these systems are interpretable is both a technical challenge and a moral imperative.

Outputs:

[Graph Your Own Prompt](https://darcyddx.github.io/files/neurips25_graph_camera.pdf), Advances in Neural Information Processing Systems (NeurIPS) 2025

[Subspace Kernel Learning on Tensor Sequences](), International Conference on Learning Representations (ICLR) 2026

[Learning Time in Static Classifiers](https://darcyddx.github.io/files/AAAI26_Learning_Time_in_Static_C.pdf), AAAI Conference on Artificial Intelligence (AAAI) 2026

---
<!-- need to put images/videos in the left, words in the right -->

### ANU TechLauncher - TIME Lab’s TIME Space [Ongoing]
The [TechLauncher program](https://comp.anu.edu.au/TechLauncher/) is for team-based activities at ANU, where the project and group activity undertaken is real, not synthetic.

The [TIME Lab](https://time.griffith.edu.au/) brings together honours and master’s students working on innovative final-year research projects that balance technical achievement with creativity and collaboration. The TIME Space project aims to design and develop an interactive digital platform to showcase the memorable moments of the past year at TIME Lab. This platform will feature a dynamic photo experience where images loop continuously in motion inspired by the TIME Lab logo. Users will be able to navigate the space by selecting specific time frames, locations, or individuals, creating a personalized and immersive way to relive shared experiences.

Objectives include: (i) Full-stack development: Build a scalable web application with advanced frontend and backend functionality, integrating cloud deployment and database management. (ii) Intelligent interaction: Apply machine learning techniques for smart tagging and image processing, enabling intuitive search and navigation through memories. (iii) Engaging UX/UI: Design and implement a user-friendly, visually dynamic interface that encourages exploration and interaction.

---

### ANU TechLauncher - Active Vision Project [Completed]

The [TechLauncher program](https://comp.anu.edu.au/TechLauncher/) is for team-based activities at ANU, where the project and group activity undertaken is real, not synthetic.

The Active Vision project aims to develop an advanced computer vision system that analyzes the dynamics of tennis swings. Using cutting-edge machine learning techniques, this project focuses on capturing and analyzing motion data to provide players and coaches with detailed insights into swing mechanics. The system leverages high-speed cameras and advanced algorithms to track, interpret, and visualize the movements of a player's body and racket, enabling precise performance assessment and improvement.

Objectives include: (i) Develop analytical algorithms: Create robust algorithms capable of analyzing the captured motion data to identify key performance indicators (KPIs) such as swing speed, angle, and impact accuracy. (ii) Real-time feedback: Implement a real-time feedback system that provides immediate insights and suggestions to players, enhancing their ability to correct and refine their techniques on the spot. (iii) User-friendly interface: Develop an intuitive interface that allows users to easily interact with the system, view their performance data, and track their progress over time.

Outputs:
[2025 S1 Poster](https://darcyddx.github.io/files/25-S1-2-Active-Vision.pdf), [2024 S2 Poster](https://darcyddx.github.io/files/24-S2-2-Active-Vision.png)

---

### Image Embedding Explorer [Completed]

We developed an innovative tool that allows users to visually navigate the high-dimensional space of image embeddings. By leveraging a technique known as projection pursuit, the tool creates dynamic 3D projections of the embedding space, offering an intuitive way to explore its structure. Each point in this space can be interactively rendered as the original image, making it easier to understand and interpret the relationships between images and their embeddings.

[Project paper](https://darcyddx.github.io/files/IEE.pdf)



